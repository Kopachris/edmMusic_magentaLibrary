# edmMusic_magentaLibrary
Using Tensorflow's Magenta Library, I trained a polyphonic RNN on edm midi files to create a neural network that generates new midi files 
for use in edm creation.

For instructions on how to run my code and use magenta please follow the link to the Tensorflow's Magenta gitub:
  - Magenta Github: https://github.com/tensorflow/magenta
  - Polyphonic_Rnn: https://github.com/tensorflow/magenta/tree/master/magenta/models/polyphony_rnn
  
magentaTrial_Demonstration.ipynb (jupyter notebook)
  - This file is a demonstration of magenta on a random midi file using a pretrained polyphony_rnn model provided by magenta
  
magentaModel.ipynb (jupyter notebook)
  - This file is the code I used to train the modelmodel
  
trainedPolyphony_rnn4584.mag (model file)
  - This file is the final and best model saved from training. It had an accuracy metric of .957...
  
data (folder)
  - This folder contains all the midi files I trained on. I had to convert the midi files into a single notes array which was then broken 
  up into sequences for training. This data processing is shown in the magentaModel.ipynb file.
  -Artists used include: Steve Aoki, San Holo, Avicii, K-391, and Alan Walker
  
samples (folder)
  - This folder contains 15 samples generated by the model. They are not edm music, they are midi files. I do not have the software to 
  convert them into mp3 edm files. (If you do, help me out???:)???)
